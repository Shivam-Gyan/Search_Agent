# ðŸ¤– LangChain - Chat with Search (Wikipedia + Arxiv + DuckDuckGo)

An interactive **AI-powered search assistant** built using **LangChain**, **Groq LLMs**, and **Streamlit**. This tool allows users to ask questions and get real-time responses pulled from:
- ðŸ§  Wikipedia  
- ðŸ“š Arxiv (research papers)  
- ðŸŒ DuckDuckGo (web search)

---

## ðŸŽ¥ Demo Video

ðŸ‘‰ [Watch Demo on Google Drive](https://drive.google.com/file/d/13O07_ogovTOHM3jm_JCvm8Z-6fhmAMZJ/view)

---

## ðŸ–¼ï¸ Screenshot

![App Screenshot](https://drive.google.com/uc?export=view&id=1ecOkOmGd-e1gI905UEvIC2CUhHTZ292h)

---

## ðŸ§  How It Works

1. The user types a query into the chat.
2. The app uses **LangChain agents** to:
   - Search relevant sources using Arxiv, Wikipedia, and DuckDuckGo.
   - Retrieve and summarize content using a **Groq-hosted LLM** (`Llama3-8b-8192`).
3. Results are streamed back with **thought-action-observation** style reasoning via `StreamlitCallbackHandler`.

---

## ðŸ› ï¸ Tech Stack

| Component            | Tool / Library                          |
|----------------------|------------------------------------------|
| UI Framework         | Streamlit                                |
| LLM Backend          | Groq (`Llama3-8b-8192`)                  |
| Retrieval Wrappers   | LangChain Community (Arxiv, Wikipedia)   |
| Web Search           | DuckDuckGo via `duckduckgo-search`       |
| LangChain Orchestration | Agents + Tools + Memory               |
| Environment Config   | python-dotenv                            |

---

## ðŸ“ Folder Structure

```

langchain-chat-search/
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ .env                 # Environment file (HF\_TOKEN)
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation

````

---

## ðŸ§ª Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/langchain-chat-search.git
cd langchain-chat-search
````

### 2. Create virtual environment

```bash
python -m venv venv
# Activate the environment:
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Add environment variables

Create a `.env` file:

```env
HF_TOKEN="your_huggingface_token"
```

You'll input the **Groq API Key** directly in the app sidebar during runtime.

### 5. Run the app

```bash
streamlit run app.py
```

---

## ðŸ§° Requirements

`requirements.txt`:

```
langchain
python-dotenv
langchain-community
bs4
langchain-text-splitters
sentence_transformers
langchain_huggingface
faiss-cpu
beautifulsoup4
langchain_groq
langchain_core
arxiv
wikipedia
streamlit
duckduckgo-search
```

---

## âœ¨ Features

* ðŸ” Real-time multi-source search (Wikipedia, Arxiv, DuckDuckGo)
* ðŸ’¬ Chat interface with session memory
* ðŸ§  LLM-backed reasoning and summarization
* ðŸ” Streams live responses with intermediate steps (`Thought â†’ Action â†’ Observation`)

---

## ðŸ“š Use Cases

* Academic research assistant
* General-purpose conversational search
* AI-powered learning companion
* PDF + Web knowledge combo agents (extensible)

---

## ðŸ” API Keys Required

* ðŸ§  [Groq API Key](https://console.groq.com/)
* ðŸ”¤ [HuggingFace Token](https://huggingface.co/settings/tokens)

---

## ðŸ§‘â€ðŸ’» Author

> Built with â¤ï¸ by \[Shivam Gupta]
> GitHub: [@Shivam-Gyan](https://github.com/Shivam-Gyan/Search_Agent)
> LinkedIn: [@shivam-gupta19](https://www.linkedin.com/in/shivam-gupta19/)

---

